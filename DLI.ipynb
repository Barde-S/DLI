{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Barde-S/DLI/blob/main/DLI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "502a7fcd"
      },
      "outputs": [],
      "source": [
        "!pip install torchinfo --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cJzHHv2c2imB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchinfo import summary\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "import gdown\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from torchvision import models\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzo6VD2PAcTu",
        "outputId": "e814034f-d23d-4923-a3f0-cafadf800dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU device.\n"
          ]
        }
      ],
      "source": [
        "# Check if CUDA-enabled GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    device = \"GPU\"  # Use GPU if available\n",
        "# Check if MPS (Metal Performance Shaders) is available for Apple Silicon\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"MPS\"  # Use MPS if available\n",
        "else:\n",
        "    device = \"CPU\"  # Fall back to CPU if no GPU or MPS available\n",
        "\n",
        "# Print the selected device type\n",
        "print(f\"Using {device} device.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIZ1PAu8DZ3A",
        "outputId": "b73478d8-d0d7-415f-d346-fedcaed4b6f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU device.\n"
          ]
        }
      ],
      "source": [
        "if torch.backends.mps.is_available():\n",
        "    device = \"MPS\"\n",
        "\n",
        "print(f\"Using {device} device.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "1AVF2gWQOelP",
        "outputId": "ececa9f1-5eef-4234-89ac-c1f91cebd8d0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-43dfd915-7db4-4ad2-b75b-63b72592a22c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-43dfd915-7db4-4ad2-b75b-63b72592a22c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "dxSiiixo8h_Q",
        "outputId": "653fe0d8-6c77-48df-f91d-66f7a24ead86"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'dataset_split.zip'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-3614398296.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset_split.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/DLI'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset_split.zip'"
          ]
        }
      ],
      "source": [
        "with zipfile.ZipFile('dataset_split.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/DLI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV8-H0EwJk9y"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/DLI/dataset_split 2'\n",
        "\n",
        "for file in os.listdir(train_dir):\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gVWSstQ4boo"
      },
      "outputs": [],
      "source": [
        "ds_store_path = os.path.join(train_dir, '.DS_Store')\n",
        "\n",
        "if os.path.exists(ds_store_path):\n",
        "    os.remove(ds_store_path)\n",
        "    print(\"Removed .DS_Store\")\n",
        "else:\n",
        "    print(\".DS_Store not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaP06bsMqq7g"
      },
      "outputs": [],
      "source": [
        "classes = os.listdir(train_dir)\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiPNmXeIrWAp"
      },
      "outputs": [],
      "source": [
        "height = 224\n",
        "width = 224\n",
        "\n",
        "\n",
        "class ConvertToRGB:\n",
        "    def __call__(self, img):\n",
        "        if img.mode != \"RGB\":\n",
        "            img = img.convert(\"RGB\")\n",
        "        return img\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    ConvertToRGB(),\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "print(transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lii5XIY3sQ2c"
      },
      "outputs": [],
      "source": [
        "sample_file = \"/content/DLI/dataset_split 2/train/Acute Otitis Media/aom (1).jpg\"\n",
        "\n",
        "image = Image.open(sample_file)\n",
        "\n",
        "transformed_image = transform(image)\n",
        "print(transformed_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MnZuzsjtEi0"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "print(\"Image size\", dataset[0][0].shape)\n",
        "print(\"Label\", dataset[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKJIm1BdvKYr"
      },
      "outputs": [],
      "source": [
        "def remove_corrupted_images(folder):\n",
        "    removed = 0\n",
        "    for root, _, files in os.walk(folder):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.verify()  # Quick image check\n",
        "            except (UnidentifiedImageError, OSError):\n",
        "                print(f\"Removing corrupted image: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "                removed += 1\n",
        "    print(f\"Total corrupted images removed: {removed}\")\n",
        "\n",
        "# Run it on your dataset path\n",
        "remove_corrupted_images('/content/DLI/dataset_split 2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xzyc-3sstKFQ"
      },
      "outputs": [],
      "source": [
        "# counts = Counter()\n",
        "# for i in tqdm(range(len(dataset))):\n",
        "#     try:\n",
        "#         # Access the item to trigger the image loading and potentially the error\n",
        "#         x = dataset[i]\n",
        "#         counts[x[1]] += 1\n",
        "#     except UnidentifiedImageError:\n",
        "#         print(f\"Skipping file {dataset.samples[i][0]} due to UnidentifiedImageError\")\n",
        "#         continue\n",
        "\n",
        "# print(\"The counts dictionary:\", counts)\n",
        "\n",
        "# # This dictionary maps class names to their index.\n",
        "# print(\"The class_to_idx dictionary:\", dataset.class_to_idx)\n",
        "\n",
        "\n",
        "# class_distribution = ({cat: counts[idx] for cat, idx in dataset.class_to_idx.items()} )\n",
        "# print(class_distribution)\n",
        "\n",
        "\n",
        "counts = Counter(x[1] for x in tqdm(dataset))\n",
        "print(\"The counts dictionary:\", counts)\n",
        "\n",
        "# This dictionary maps class names to their index.\n",
        "print(\"The class_to_idx dictionary:\", dataset.class_to_idx)\n",
        "\n",
        "# Use both of these to construct the desired dictionary\n",
        "\n",
        "class_distribution = ({cat: counts[idx] for cat, idx in dataset.class_to_idx.items()} )\n",
        "print(class_distribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxvKRXNktVdy"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "dataset_loader = DataLoader(dataset, batch_size=32)\n",
        "\n",
        "# Get one batch\n",
        "first_batch = next(iter(dataset_loader))\n",
        "\n",
        "print(f\"Shape of one batch: {first_batch[0].shape}\")\n",
        "print(f\"Shape of labels: {first_batch[1].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmRUvU28ttI5"
      },
      "outputs": [],
      "source": [
        "def get_mean_std(loader):\n",
        "    \"\"\"Computes the mean and standard deviation of image data.\n",
        "\n",
        "     (ideally we caan have this in a separate .py file to just import the function)\n",
        "            \"\"\"\n",
        "\n",
        "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "    for data, _ in tqdm(loader):\n",
        "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
        "        channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
        "        num_batches += 1\n",
        "    # Compute the mean from the channels_sum and num_batches\n",
        "    mean = channels_sum/num_batches\n",
        "    # Compute the standard deviation form channels_squared_sum, num_batches,\n",
        "    # and the mean.\n",
        "    std = torch.sqrt((channels_squared_sum / num_batches) - (mean**2))\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "\n",
        "mean, std = get_mean_std(dataset_loader)\n",
        "\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Standard deviation: {std}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LskofccLuFMs"
      },
      "outputs": [],
      "source": [
        "mean = [0.4834, 0.3793, 0.3572]\n",
        "std = [0.2586, 0.2419, 0.2436]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sor4a0hnvxVt"
      },
      "outputs": [],
      "source": [
        "transform_norm = transforms.Compose([\n",
        "    ConvertToRGB(),\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std),\n",
        "])\n",
        "print(transform_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nThUPiDsv3sZ"
      },
      "outputs": [],
      "source": [
        "norm_dataset = datasets.ImageFolder(root=train_dir, transform=transform_norm)\n",
        "\n",
        "print(\"Image size\", norm_dataset[0][0].shape)\n",
        "print(\"Label\", norm_dataset[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVDs87d2v6_c"
      },
      "outputs": [],
      "source": [
        "g = torch.Generator()\n",
        "train_dataset, val_dataset = random_split(norm_dataset, [.8,.2], generator=g)\n",
        "\n",
        "print(\"Training data set size:\", len(train_dataset))\n",
        "print(\"Validation data set size:\", len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tw46F2K_6K4R"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4YZlwZ06SEH"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, optimizer, loss_fn, data_loader, device=\"cpu\"):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "\n",
        "    for inputs, targets in tqdm(data_loader, desc=\"Training\", leave=False):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)\n",
        "        loss = loss_fn(output, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * inputs.size(0)\n",
        "        preds = torch.argmax(output, dim=1)\n",
        "        total_correct += torch.sum(preds == targets).item()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader.dataset)\n",
        "    accuracy = total_correct / len(data_loader.dataset)\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def predict(model, data_loader, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in tqdm(data_loader, desc=\"Predicting\", leave=False):\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            probs = torch.nn.functional.softmax(output, dim=1)\n",
        "            all_probs.append(probs.cpu())\n",
        "\n",
        "    return torch.cat(all_probs, dim=0)\n",
        "\n",
        "\n",
        "# 3. Score a model on a dataset (validation or test)\n",
        "def score(model, data_loader, loss_fn, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in tqdm(data_loader, desc=\"Scoring\", leave=False):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            output = model(inputs)\n",
        "            loss = loss_fn(output, targets)\n",
        "\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "            total_correct += torch.sum(preds == targets).item()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader.dataset)\n",
        "    accuracy = total_correct / len(data_loader.dataset)\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "# 4. Full training loop\n",
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # Train\n",
        "        train_loss, train_accuracy = train_epoch(model, optimizer, loss_fn, train_loader, device)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Validate\n",
        "        val_loss, val_accuracy = score(model, val_loader, loss_fn, device)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        # Print status\n",
        "        print(\n",
        "            f\"Epoch {epoch:02d} | \"\n",
        "            f\"Train Loss: {train_loss:.4f} | Train Acc: {train_accuracy:.4f} | \"\n",
        "            f\"Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.4f}\"\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, train_accuracies, val_accuracies\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def early_stopping(validation_loss, best_val_loss, counter):\n",
        "    \"\"\"Function that implements Early Stopping\"\"\"\n",
        "\n",
        "    stop = False\n",
        "\n",
        "    if validation_loss < best_val_loss:\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    if counter >= 5:  # our patience is 5 epochs\n",
        "        stop = True\n",
        "\n",
        "    return counter, stop\n",
        "\n",
        "\n",
        "def checkpointing(validation_loss, best_val_loss, model, optimizer, save_path):\n",
        "    \"\"\"Function that implements Checkpointing\"\"\"\n",
        "\n",
        "    if validation_loss < best_val_loss:\n",
        "        torch.save(\n",
        "            {\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"loss\": best_val_loss,\n",
        "            },\n",
        "            save_path,\n",
        "        )\n",
        "        print(f\"Checkpoint saved with validation loss {validation_loss:.4f}\")\n",
        "\n",
        "\n",
        "def train_callbacks(\n",
        "    model,\n",
        "    optimizer,\n",
        "    loss_fn,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=20,\n",
        "    device=\"cpu\",\n",
        "    scheduler=None,\n",
        "    checkpoint_path=None,\n",
        "    early_stopping=None,\n",
        "):\n",
        "    # Track the model progress over epochs\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    learning_rates = []\n",
        "\n",
        "    # Create the trackers if needed for checkpointing and early stopping\n",
        "    best_val_loss = float(\"inf\")\n",
        "    early_stopping_counter = 0\n",
        "\n",
        "    print(\"Model evaluation before start of training...\")\n",
        "    # Test on training set\n",
        "    train_loss, train_accuracy = score(model, train_loader, loss_fn, device)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    # Test on validation set\n",
        "    validation_loss, validation_accuracy = score(model, val_loader, loss_fn, device)\n",
        "    val_losses.append(validation_loss)\n",
        "    val_accuracies.append(validation_accuracy)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(\"\\n\")\n",
        "        print(f\"Starting epoch {epoch}/{epochs}\")\n",
        "\n",
        "        # Train one epoch\n",
        "        train_epoch(model, optimizer, loss_fn, train_loader, device)\n",
        "\n",
        "        # Evaluate training results\n",
        "        train_loss, train_accuracy = score(model, train_loader, loss_fn, device)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Test on validation set\n",
        "        validation_loss, validation_accuracy = score(model, val_loader, loss_fn, device)\n",
        "        val_losses.append(validation_loss)\n",
        "        val_accuracies.append(validation_accuracy)\n",
        "\n",
        "        print(f\"Epoch: {epoch}\")\n",
        "        print(f\"Training loss: {train_loss:.4f}\")\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "        print(f\"Validation loss: {validation_loss:.4f}\")\n",
        "        print(f\"Validation accuracy: {validation_accuracy*100:.2f}%\")\n",
        "\n",
        "        # # Log the learning rate and have the scheduler adjust it\n",
        "        lr = optimizer.param_groups[0][\"lr\"]\n",
        "        learning_rates.append(lr)\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Checkpointing saves the model if current model is better than best so far\n",
        "        if checkpoint_path:\n",
        "            checkpointing(\n",
        "                validation_loss, best_val_loss, model, optimizer, checkpoint_path\n",
        "            )\n",
        "\n",
        "        # Early Stopping\n",
        "        if early_stopping:\n",
        "            early_stopping_counter, stop = early_stopping(\n",
        "                validation_loss, best_val_loss, early_stopping_counter\n",
        "            )\n",
        "\n",
        "            if stop:\n",
        "                print(f\"Early stopping triggered after {epoch} epochs\")\n",
        "                break\n",
        "\n",
        "        if validation_loss < best_val_loss:\n",
        "            best_val_loss = validation_loss\n",
        "\n",
        "    return (\n",
        "        learning_rates,\n",
        "        train_losses,\n",
        "        val_losses,\n",
        "        train_accuracies,\n",
        "        val_accuracies,\n",
        "        epoch,\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfJlIzYcCnbm"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "model = torch.nn.Sequential()\n",
        "\n",
        "conv1_n_kernels = 16\n",
        "conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1)\n",
        "max_pool_size = 4\n",
        "max_pool1 = torch.nn.MaxPool2d(max_pool_size)\n",
        "model.append(conv1)\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(max_pool1)\n",
        "\n",
        "conv2_n_kernels = 32\n",
        "conv2 = torch.nn.Conv2d(\n",
        "    in_channels=16, out_channels=conv2_n_kernels, kernel_size=(3, 3), padding=1\n",
        ")\n",
        "max_pool2 = torch.nn.MaxPool2d(max_pool_size)\n",
        "model.append(conv2)\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(max_pool2)\n",
        "\n",
        "conv3_n_kernels = 64\n",
        "conv3 = torch.nn.Conv2d(32, conv3_n_kernels, 3, padding=1)\n",
        "max_pool3 = torch.nn.MaxPool2d(max_pool_size)\n",
        "model.append(conv3)\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(max_pool3)\n",
        "\n",
        "model.append(torch.nn.AdaptiveAvgPool2d((1, 1)))\n",
        "model.append(torch.nn.Flatten())\n",
        "model.append(torch.nn.Linear(64, 500))  # 64 is from conv3_n_kernels\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(torch.nn.Dropout())\n",
        "\n",
        "n_classes = 5\n",
        "output_layer = torch.nn.Linear(500, n_classes)\n",
        "model.append(output_layer)\n",
        "\n",
        "summary(model, input_size=(batch_size, 3, height, width))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTD8Cr54CsLl"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "model.to(device)\n",
        "print(loss_fn)\n",
        "print(\"----------------------\")\n",
        "print(optimizer)\n",
        "print(\"----------------------\")\n",
        "print(next(model.parameters()).device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ACJH75vC2nc"
      },
      "outputs": [],
      "source": [
        "epochs = 15\n",
        "\n",
        "train_losses, val_losses, train_accuracies, val_accuracies = train(\n",
        "    model, optimizer, loss_fn, train_loader, val_loader, epochs, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvWLaCiOEJJ3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label=\"Training Loss\")\n",
        "plt.plot(val_losses, label=\"Validation Loss\")\n",
        "plt.title(\"Loss over epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label=\"Training Accuracy\")\n",
        "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
        "plt.title(\"Accuracy over epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGTTVBspOJc6"
      },
      "outputs": [],
      "source": [
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrr7ceu6OdJW"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if \"layer4\" in name or \"fc\" in name:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dqfB-bYOhmh"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "in_features = model.fc.in_features\n",
        "\n",
        "modified_last_layer = nn.Sequential()\n",
        "\n",
        "dense_layer = nn.Linear(in_features, 256)\n",
        "modified_last_layer.append(dense_layer)\n",
        "\n",
        "relu = nn.ReLU()\n",
        "modified_last_layer.append(relu)\n",
        "\n",
        "modified_last_layer.append(nn.Dropout(p=0.5))\n",
        "\n",
        "output_layer = nn.Linear(256, 5)\n",
        "modified_last_layer.append(output_layer)\n",
        "\n",
        "# Assign `modified_last_layer` to `model.fc`\n",
        "model.fc = modified_last_layer\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l_jqCnxOn1r"
      },
      "outputs": [],
      "source": [
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=g)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBiS9gymSXhn"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "# Place the model on device\n",
        "model.to(device)\n",
        "\n",
        "# Train the model for 10 epochs\n",
        "epochs = 10\n",
        "train_losses, val_losses, train_accuracies, val_accuracies = train(\n",
        "    model, optimizer, loss_fn, train_loader, val_loader, epochs, device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_GxUjooSbrp"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label=\"Training Loss\")\n",
        "plt.plot(val_losses, label=\"Validation Loss\")\n",
        "plt.title(\"Loss over epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label=\"Training Accuracy\")\n",
        "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
        "plt.title(\"Accuracy over epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLJt2Uw_UD4Z"
      },
      "outputs": [],
      "source": [
        "test_dir = os.path.join(\"/content/DLI/dataset_split 2\", \"test\")\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform_norm)\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=False\n",
        ")\n",
        "\n",
        "print(\"Number of test images:\", len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AxECOG6mH1t"
      },
      "outputs": [],
      "source": [
        "# Predict the probabilities for each test image\n",
        "test_probabilities = predict(model, test_loader, device)\n",
        "\n",
        "# Get the index with the largest probability\n",
        "test_predictions = torch.argmax(test_probabilities, dim=1)\n",
        "\n",
        "# way to get class names\n",
        "test_classes = [test_dataset.classes[i] for i in test_predictions]\n",
        "\n",
        "# Output\n",
        "print(\"Number of predictions:\", test_predictions.shape)\n",
        "print(\"Predictions (class index):\", test_predictions.tolist())\n",
        "print(\"Predictions (class name):\", test_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gS4Qlo6VU3Hv"
      },
      "outputs": [],
      "source": [
        "epochs_to_train = 50\n",
        "checkpoint_path = \"LR_model.pth\"\n",
        "early_stopping_function = early_stopping\n",
        "\n",
        "train_results = train_callbacks(\n",
        "   model,\n",
        "   optimizer,\n",
        "   loss_fn,\n",
        "   train_loader,\n",
        "   val_loader,\n",
        "   epochs=epochs_to_train,\n",
        "   device=device,\n",
        "   checkpoint_path=checkpoint_path,\n",
        "   early_stopping=early_stopping_function,\n",
        "   scheduler=scheduler\n",
        ")\n",
        "\n",
        "\n",
        "(\n",
        "    learning_rates,\n",
        "    train_losses,\n",
        "    valid_losses,\n",
        "    train_accuracies,\n",
        "    valid_accuracies,\n",
        "    epochs,\n",
        ") = train_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dryrJmLQZif9"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "# Collect all predictions and true labels\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_targets.extend(targets.cpu().numpy())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SjF96bzKzip"
      },
      "outputs": [],
      "source": [
        "# evaluation metrics\n",
        "accuracy = accuracy_score(all_targets, all_preds)\n",
        "precision = precision_score(all_targets, all_preds, average='weighted', zero_division=0)\n",
        "recall = recall_score(all_targets, all_preds, average='weighted', zero_division=0)\n",
        "f1 = f1_score(all_targets, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnNtvvLEK-Vr"
      },
      "outputs": [],
      "source": [
        "# classification report\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(all_targets, all_preds, target_names=test_dataset.classes))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zGa9bEbLANH"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_targets, all_preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=test_dataset.classes,\n",
        "            yticklabels=test_dataset.classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNDpj8qKMwxJ7igenKINe1k",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}